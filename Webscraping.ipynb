{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Webscrape Human Genome Dataset__\n",
    "\n",
    "- In order to map the population codes to each individual sample I went on to the Genome_Website and scraped the population samples along with their corresponding population code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/AlexGaujean/anaconda3/lib/python3.7/site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /Users/AlexGaujean/anaconda3/lib/python3.7/site-packages (from selenium) (1.24.1)\n",
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/AlexGaujean/anaconda3/lib/python3.7/site-packages (from bs4) (4.6.3)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/AlexGaujean/Library/Caches/pip/wheels/a0/b0/b2/4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install necessary modules\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save variables for each row in our main population genome table  \n",
    "page = requests.get('http://www.internationalgenome.org/cell-lines-and-dna-coriell')\n",
    "soup = BeautifulSoup(page.content, 'lxml') \n",
    "\n",
    "popcode = soup.find('tr')\n",
    "popcode = soup.findAll('tr')\n",
    "#collect the more specific population descriptions \n",
    "population_descriptions = [x.td.text for x in popcode[1:]]\n",
    "#collect URLs for individual sample names\n",
    "hrefs = [x.td.next_sibling.next_sibling.next_sibling.next_sibling.a['href'] for x in popcode[1:]]\n",
    "#collect the population codes for each of our subsamples\n",
    "population_code = [x.td.next_sibling.next_sibling.text for x in popcode[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FIN'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a population_dict where we will store our dictionary values and zip that with the corresponding 'href' tags that we found online\n",
    "population_dict = {}\n",
    "zipped_list = zip(population_code, hrefs)\n",
    "list(zipped_list)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a for loop that will go through our reference genome website and scrape all of the individual sample accounts\n",
    "population_dict = {}\n",
    "zipped_list = zip(population_code, hrefs)\n",
    "#setup chrome driver to scrape the tables for population codes\n",
    "browser = webdriver.Chrome('/Users/AlexGaujean/Desktop/chromedriver')\n",
    "time.sleep(5)\n",
    "# loop through our list of links\n",
    "for i in zipped_list:\n",
    "    browser.get(i[1])\n",
    "    ## code for webscraping with selenium ##\n",
    "    table = browser.find_element_by_xpath('//*[@id=\"grdRef\"]')\n",
    "        #get all of the rows in the table\n",
    "    try: \n",
    "        rows = table.find_elements_by_tag_name('tr')\n",
    "        #setup list called sample which we are going to use to append our sample_codes\n",
    "        sample = []\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find_elements_by_tag_name('td')\n",
    "            sample.append(cols[0].text)\n",
    "    except IndexError: \n",
    "        rows = table.find_elements_by_tag_name('tr')\n",
    "        sample = []\n",
    "        for row in rows[3:]:\n",
    "            cols = row.find_elements_by_tag_name('td')\n",
    "            sample.append(cols[0].text) \n",
    "    population_dict[i[0]] = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out all the webscraped tables that skipped values \n",
    "def popcode_filter(dictionary_key): \n",
    "    dictionary_key = list(filter(lambda x: not (x == \" \"), dictionary_key))\n",
    "popcode_filter(population_dict['MXL'])\n",
    "popcode_filter(population_dict['ASW'])\n",
    "popcode_filter(population_dict['YRI']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finnish_in_Finland = population_dict['FIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HG00171',\n",
       " 'HG00173',\n",
       " 'HG00174',\n",
       " 'HG00176',\n",
       " 'HG00177',\n",
       " 'HG00178',\n",
       " 'HG00179',\n",
       " 'HG00180',\n",
       " 'HG00266',\n",
       " 'HG00268',\n",
       " 'HG00269',\n",
       " 'HG00270',\n",
       " 'HG00272',\n",
       " 'HG00274',\n",
       " 'HG00275',\n",
       " 'HG00276',\n",
       " 'HG00281',\n",
       " 'HG00282',\n",
       " 'HG00285',\n",
       " 'HG00306',\n",
       " 'HG00309',\n",
       " 'HG00313',\n",
       " 'HG00315',\n",
       " 'HG00318',\n",
       " 'HG00319',\n",
       " 'HG00320',\n",
       " 'HG00323',\n",
       " 'HG00324',\n",
       " 'HG00326',\n",
       " 'HG00327',\n",
       " 'HG00328',\n",
       " 'HG00330',\n",
       " 'HG00331',\n",
       " 'HG00332',\n",
       " 'HG00334',\n",
       " 'HG00337',\n",
       " 'HG00339',\n",
       " 'HG00343',\n",
       " 'HG00344',\n",
       " 'HG00346',\n",
       " 'HG00349',\n",
       " 'HG00350',\n",
       " 'HG00353',\n",
       " 'HG00355',\n",
       " 'HG00356',\n",
       " 'HG00357',\n",
       " 'HG00359',\n",
       " 'HG00361',\n",
       " 'HG00362',\n",
       " 'HG00364',\n",
       " 'HG00365',\n",
       " 'HG00367',\n",
       " 'HG00368',\n",
       " 'HG00373',\n",
       " 'HG00376',\n",
       " 'HG00377',\n",
       " 'HG00378',\n",
       " 'HG00379',\n",
       " 'HG00380',\n",
       " 'HG00381',\n",
       " 'HG00383',\n",
       " 'HG00384',\n",
       " 'HG00181',\n",
       " 'HG00182',\n",
       " 'HG00183',\n",
       " 'HG00185',\n",
       " 'HG00186',\n",
       " 'HG00187',\n",
       " 'HG00188',\n",
       " 'HG00189',\n",
       " 'HG00190',\n",
       " 'HG00267',\n",
       " 'HG00271',\n",
       " 'HG00273',\n",
       " 'HG00277',\n",
       " 'HG00278',\n",
       " 'HG00280',\n",
       " 'HG00284',\n",
       " 'HG00308',\n",
       " 'HG00310',\n",
       " 'HG00311',\n",
       " 'HG00312',\n",
       " 'HG00321',\n",
       " 'HG00325',\n",
       " 'HG00329',\n",
       " 'HG00335',\n",
       " 'HG00336',\n",
       " 'HG00338',\n",
       " 'HG00341',\n",
       " 'HG00342',\n",
       " 'HG00345',\n",
       " 'HG00351',\n",
       " 'HG00358',\n",
       " 'HG00360',\n",
       " 'HG00366',\n",
       " 'HG00369',\n",
       " 'HG00371',\n",
       " 'HG00372',\n",
       " 'HG00375',\n",
       " 'HG00382']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Finnish_in_Finland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
